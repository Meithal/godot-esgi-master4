{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3aaefb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd57a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_outer():\n",
    "    pass\n",
    "\n",
    "class MyMLP:\n",
    "\n",
    "    def __init__(self, neurons_per_layer: list[int]):\n",
    "        self.d = list(neurons_per_layer)  # neurons_per_layer (input included)\n",
    "        self.L = len(self.d) - 1\n",
    "        self.W = []\n",
    "        #self.W[l][i][j]\n",
    "        for l in range(len(self.d)):\n",
    "            self.W.append([])\n",
    "            if l == 0:\n",
    "                continue\n",
    "            for i in range(self.d[l - 1] + 1):  # +1 compte le neurone de biais fictif\n",
    "                self.W[l].append([])\n",
    "                for j in range(self.d[l] + 1):\n",
    "                    rdm = random.random() * 2 - 1\n",
    "                    self.W[l][i].append(0.0 if j == 0 else rdm)\n",
    "        self.X = []\n",
    "        self.deltas = []\n",
    "\n",
    "        for l in range(len(self.d)):\n",
    "            self.X.append([])\n",
    "            self.deltas.append([])\n",
    "\n",
    "            for j in range(self.d[l] + 1):\n",
    "                self.X[l].append(1.0 if j == 0 else 0.0)\n",
    "                self.deltas[l].append(0.0)\n",
    "\n",
    "    def _propagate(self, inputs: list[float], is_classification : bool):\n",
    "        assert len(inputs) == self.d[0]\n",
    "        for j in range(len(inputs)):\n",
    "            self.X[0][j+1] = inputs[j]\n",
    "\n",
    "        for l in range(1, self.L+1):\n",
    "            for j in range(1, self.d[l] + 1):\n",
    "                signal = 0\n",
    "                for i in range(self.d[l-1] + 1):\n",
    "                    signal += self.W[l][i][j] * self.X[l - 1][i]\n",
    "                x = signal\n",
    "                if is_classification or l != self.L:\n",
    "                    x = math.tanh(signal)\n",
    "                self.X[l][j] = x\n",
    "\n",
    "    def predict(self, inputs: list[float], is_classification: bool):\n",
    "        self._propagate(inputs, is_classification)\n",
    "        return self.X[self.L]\n",
    "    \n",
    "    def train(self, \n",
    "              all_samples_inputs:list[list[float]],\n",
    "                all_samples_expected_outputs: list[list[float]],\n",
    "                is_classification: bool,\n",
    "                num_iter: int,\n",
    "                alpha: float # learning rate\n",
    "              \n",
    "              ):\n",
    "        assert len(all_samples_inputs) == len(all_samples_expected_outputs)\n",
    "\n",
    "        for _ in tqdm(range(num_iter)):\n",
    "            k = random.randint(0, len(all_samples_inputs) - 1)\n",
    "            inputs_k = all_samples_inputs[k]\n",
    "            outputs_k = all_samples_expected_outputs[k]\n",
    "\n",
    "            self._propagate(inputs_k, is_classification)  # mise a jour des xij\n",
    "            for j in range(self.d[self.L] + 1):\n",
    "                # self.deltas[self.L][j] = (1.0 - self.X[self.L][j] ** 2) * (self.X[L])\n",
    "                if is_classification:\n",
    "                    self.deltas[self.L][j] *= (1.0 - self.X[self.L][j] ** 2)\n",
    "\n",
    "            for l in reversed(range(2, self.L + 1)):\n",
    "                for i in range(1, self.d[self.L-1] + 1):\n",
    "                    total = 0\n",
    "                    for j in range(1, self.d[l] + 1):\n",
    "                        total += self.W[l][i][j] * self.deltas[i][j]\n",
    "                    total *= (1.0 - self.X[l - 1][i] ** 2)\n",
    "                    self.deltas[l - 1][i] = total\n",
    "            for l in range(1, self.L + 1):\n",
    "                for i in range(self.d[i-1] + 1):\n",
    "                    for j in range(1, self.d[l] + 1):\n",
    "                        self.W[l][i][j] = self.W[l][i][j] - alpha * self.X[l-1][i] * self.deltas[l][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d80ee7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.7393354049350186]\n"
     ]
    }
   ],
   "source": [
    "mlp = MyMLP([2, 3, 1])\n",
    "mlp.W\n",
    "print(mlp.predict([-42.0, 42.0], True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da6c0973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.08614693298269892]\n",
      "[1.0, 0.19847343792666028]\n",
      "[1.0, 0.4320379896678563]\n",
      "[1.0, 0.5031926585772118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m xor_inputs:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(mlp.predict(sample, \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mmlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxor_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxor_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m xor_inputs:\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(mlp.predict(sample, \u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mMyMLP.train\u001b[39m\u001b[34m(self, all_samples_inputs, all_samples_expected_outputs, is_classification, num_iter, alpha)\u001b[39m\n\u001b[32m     73\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.d[l] + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     total += \u001b[38;5;28mself\u001b[39m.W[l][i][j] * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[j]\n\u001b[32m     76\u001b[39m total *= (\u001b[32m1.0\u001b[39m - \u001b[38;5;28mself\u001b[39m.X[l - \u001b[32m1\u001b[39m][i] ** \u001b[32m2\u001b[39m)\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m.deltas[l - \u001b[32m1\u001b[39m][i] = total\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "xor_inputs = [\n",
    "    [0., 0.],\n",
    "    [1., 0.],\n",
    "    [0., 1.],\n",
    "    [1., 1.]\n",
    "]\n",
    "\n",
    "xor_outputs = [\n",
    "    [-1.],\n",
    "    [1.],\n",
    "    [1.],\n",
    "    [-1.0]\n",
    "]\n",
    "\n",
    "for sample in xor_inputs:\n",
    "    print(mlp.predict(sample, True))\n",
    "\n",
    "mlp.train(xor_inputs, xor_outputs, True, 10000, 0.01)\n",
    "\n",
    "for sample in xor_inputs:\n",
    "    print(mlp.predict(sample, True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
